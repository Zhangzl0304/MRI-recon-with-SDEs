{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import library"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "363e376610e1c6d8"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import functools\n",
    "from data_loader import TrainDatasetFolder\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T15:42:15.722464431Z",
     "start_time": "2023-11-24T15:42:15.711088660Z"
    }
   },
   "id": "e7ecdec35e1a1b7f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "backbone of the module: U-Net\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a7a32456141c266"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class GaussianFourierProjection(nn.Module):\n",
    "    \"\"\"Gaussian random features for encoding time steps.\"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim, scale=30.):\n",
    "        super().__init__()\n",
    "        # Randomly sample weights during initialization. These weights are fixed\n",
    "        # during optimization and are not trainable.\n",
    "        self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    \"\"\"A fully connected layer that reshapes outputs to feature maps.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense(x)[..., None, None]\n",
    "\n",
    "class ScoreNet(nn.Module):\n",
    "    \"\"\"A time-dependent score-based model built upon U-Net architecture.\"\"\"\n",
    "\n",
    "    def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256], embed_dim=256):\n",
    "        \"\"\"Initialize a time-dependent score-based network.\n",
    "\n",
    "        Args:\n",
    "          marginal_prob_std: A function that takes time t and gives the standard\n",
    "            deviation of the perturbation kernel p_{0t}(x(t) | x(0)).\n",
    "          channels: The number of channels for feature maps of each resolution.\n",
    "          embed_dim: The dimensionality of Gaussian random feature embeddings.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Gaussian random feature embedding layer for time\n",
    "        self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),\n",
    "                                   nn.Linear(embed_dim, embed_dim))\n",
    "        # Encoding layers where the resolution decreases\n",
    "        self.conv1 = nn.Conv2d(1, channels[0], 3, stride=1, bias=False)\n",
    "        self.dense1 = Dense(embed_dim, channels[0])\n",
    "        self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\n",
    "        self.conv2 = nn.Conv2d(channels[0], channels[1], 3, stride=2, bias=False)\n",
    "        self.dense2 = Dense(embed_dim, channels[1])\n",
    "        self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "        self.conv3 = nn.Conv2d(channels[1], channels[2], 3, stride=2, bias=False)\n",
    "        self.dense3 = Dense(embed_dim, channels[2])\n",
    "        self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "        self.conv4 = nn.Conv2d(channels[2], channels[3], 3, stride=2, bias=False)\n",
    "        self.dense4 = Dense(embed_dim, channels[3])\n",
    "        self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])\n",
    "\n",
    "        # Decoding layers where the resolution increases\n",
    "        self.tconv4 = nn.ConvTranspose2d(channels[3], channels[2], 3, stride=2, bias=False)\n",
    "        self.dense5 = Dense(embed_dim, channels[2])\n",
    "        self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "        self.tconv3 = nn.ConvTranspose2d(channels[2] + channels[2], channels[1], 3, stride=2, bias=False,\n",
    "                                         output_padding=1)\n",
    "        self.dense6 = Dense(embed_dim, channels[1])\n",
    "        self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "        self.tconv2 = nn.ConvTranspose2d(channels[1] + channels[1], channels[0], 3, stride=2, bias=False,\n",
    "                                         output_padding=1)\n",
    "        self.dense7 = Dense(embed_dim, channels[0])\n",
    "        self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\n",
    "        self.tconv1 = nn.ConvTranspose2d(channels[0] + channels[0], 1, 3, stride=1)\n",
    "\n",
    "        # The swish activation function\n",
    "        self.act = lambda x: x * torch.sigmoid(x)\n",
    "        self.marginal_prob_std = marginal_prob_std\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Obtain the Gaussian random feature embedding for t\n",
    "        embed = self.act(self.embed(t))\n",
    "        # Encoding path\n",
    "        h1 = self.conv1(x)\n",
    "        ## Incorporate information from t\n",
    "        h1 += self.dense1(embed)\n",
    "        ## Group normalization\n",
    "        h1 = self.gnorm1(h1)\n",
    "        h1 = self.act(h1)\n",
    "        h2 = self.conv2(h1)\n",
    "        h2 += self.dense2(embed)\n",
    "        h2 = self.gnorm2(h2)\n",
    "        h2 = self.act(h2)\n",
    "        h3 = self.conv3(h2)\n",
    "        h3 += self.dense3(embed)\n",
    "        h3 = self.gnorm3(h3)\n",
    "        h3 = self.act(h3)\n",
    "        h4 = self.conv4(h3)\n",
    "        h4 += self.dense4(embed)\n",
    "        h4 = self.gnorm4(h4)\n",
    "        h4 = self.act(h4)\n",
    "\n",
    "        # Decoding path\n",
    "        h = self.tconv4(h4)\n",
    "        ## Skip connection from the encoding path\n",
    "        h += self.dense5(embed)\n",
    "        h = self.tgnorm4(h)\n",
    "        h = self.act(h)\n",
    "        h = self.tconv3(torch.cat([h, h3], dim=1))\n",
    "        h += self.dense6(embed)\n",
    "        h = self.tgnorm3(h)\n",
    "        h = self.act(h)\n",
    "        h = self.tconv2(torch.cat([h, h2], dim=1))\n",
    "        h += self.dense7(embed)\n",
    "        h = self.tgnorm2(h)\n",
    "        h = self.act(h)\n",
    "        h = self.tconv1(torch.cat([h, h1], dim=1))\n",
    "\n",
    "        # Normalize output\n",
    "        h = h / self.marginal_prob_std(t)[:, None, None, None]\n",
    "        return h\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T15:42:15.762154949Z",
     "start_time": "2023-11-24T15:42:15.718681723Z"
    }
   },
   "id": "aea795b08a31bdfe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Visualize the data:\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7631efc13d14bff0"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TrainDatasetFolder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m Train_data \u001B[38;5;241m=\u001B[39m \u001B[43mTrainDatasetFolder\u001B[49m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m04\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msax\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      2\u001B[0m k_und, im_und, im_gnd, mask \u001B[38;5;241m=\u001B[39m Train_data[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;28mabs\u001B[39m(k_und[\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m,  \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m]),\n\u001B[1;32m      4\u001B[0m            cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgray\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      5\u001B[0m            )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'TrainDatasetFolder' is not defined"
     ]
    }
   ],
   "source": [
    "Train_data = TrainDatasetFolder('04','sax')\n",
    "k_und, im_und, im_gnd, mask = Train_data[0]\n",
    "plt.imshow(abs(k_und[0,0,  ...]),\n",
    "           cmap='gray'\n",
    "           )\n",
    "plt.show()\n",
    "print('1111')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T16:23:39.511179894Z",
     "start_time": "2023-11-24T16:23:39.158054591Z"
    }
   },
   "id": "bee775c61a470500"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T15:42:19.944381465Z",
     "start_time": "2023-11-24T15:42:19.942128470Z"
    }
   },
   "id": "7b280ed4216d8b11"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
